#****************************************************************************************
#*** 说明文档: 基础信息数据!
#*** 编 写 人:  wangshuai
#*** 编写日期:  2018-11-13
#*** 修 改 人:
#*** 修改日期:
#*** 备    注:
#*****************************************************************************************
#集群NameNode地址
namenode_path=hdfs://192.168.102.120:8020
#Flume采集的存放在HDFS上的路径
gz_interfacedir=/yss/guzhi/interface/
#Spark处理结果数据保存在HDFS上的路径
gz_outputdir=/yss/guzhi/hzjkqs
#Spark输入基础表数据的HDFS路径
gz_basic_list=/yss/guzhi/basic_list/
#数据库的连接配置用户名,密码,驱动
user=root
password=root1234
driver=com.mysql.jdbc.Driver
jdbc=jdbc:mysql://192.168.102.120/JJCWGZ?useUnicode=true&characterEncoding=utf8
#Spark的运行模式,local   client standalone cluster
master_type=local[*]
#zookeeper的配置
hbase.zookeeper.property.clientPort=2181
hbase.zookeeper.quorum=192.168.102.121
zookeeper.znode.parent=/hbase-unsecure